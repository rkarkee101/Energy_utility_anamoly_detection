#Part 2: Identifying Underperforming Buildings Post-Retrofit
In this part, we have two datasets (pre-retrofit and post-retrofit utility bills) for multiple schools (say 5 schools). Each dataset contains monthly energy usage per school. The goal is to find if any building is underperforming after the retrofit – meaning it did not achieve the expected energy savings (or has unusual usage patterns post-retrofit). This involves both trend anomalies (a school’s overall post-retrofit energy trend is off) and point anomalies (specific months post-retrofit that are abnormal for that school).
Approach:
1. Load Pre- and Post-Retrofit Data: Read the two CSV files preretrofit.csv and postretrofit.csv. Each should contain records of monthly energy usage for each school (with columns like School ID, billing date, electricity (kWh), gas, and square footage). 2. Normalize by Size: Compute energy use intensity (EUI) for each record, i.e., energy per square foot. This allows fair comparison between schools of different sizes. We can compute EUI for electricity and/or a combined energy metric (convert gas to kWh equivalent if needed, or handle separately). 3. Calculate Baseline vs Post-Retrofit Performance: For each school, aggregate the total (or average) annual EUI before and after retrofit. For example, sum the 12 months of kWh usage pre-retrofit and post-retrofit and divide by square footage to get annual EUI for each period. Compute the percentage change in EUI after retrofit. 4. Detect Underperformers (Building-Level Anomaly): We expect retrofits to reduce energy usage, so most schools should show a negative percentage change (i.e., lower EUI post-retrofit). An underperforming building might show much smaller reduction or even an increase in usage. We use an anomaly detection model (e.g., Isolation Forest or One-Class SVM) on the set of percentage changes to flag outliers. If one school’s performance is significantly worse than the others, it will be identified as an anomaly in this distribution. (With only ~5 schools, a simple statistical rule can also be used: e.g., any school with post-retrofit usage reduction less than, say, half the average reduction, or a positive increase, can be flagged.) 5. Identify Specific Anomalies in Usage Trends: For any flagged underperforming school, we can dig deeper. We would apply a similar approach as Part 1 to that school’s time series to find specific months or trends post-retrofit where usage was abnormally high (perhaps indicating faulty equipment or ineffective retrofit in one part of the campus). 6. Output Results: The code will list the school ID(s) that are detected as underperforming (if any), and could also highlight the anomaly points/trends in those schools.
